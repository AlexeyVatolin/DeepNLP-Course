# Лекция 4
*Рекуррентные нейронные сети, часть 2*

Ноутбук на Colab можно найти [здесь](https://colab.research.google.com/drive/1CN-OhE-mbYstkxyJ24NFcNy8SpYMAeM0).

**Задание**  
*Дедлайн: 09:00 GMT+3 29.03.18*  
1. Доделать POS-tagging модель:  
	- Реализовать masking  
	- Bidirectional LSTM  
	- Добавить словные эмбеддинги  
	- Сравнить с полносвязной сетью   
2. Реализовать словную языковую модель:  
	- N-граммную статистическую  
	- N-граммную с помощью полносвязного слоя  
	- LSTM

Дополнительные материалы:  
[Как научить свою нейросеть анализировать морфологию](https://habrahabr.ru/post/339954/)  
[Как научить свою нейросеть генерировать стихи](https://habrahabr.ru/post/334046/)  
[Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)  
[Dropout in Recurrent Networks — Part 1-3](https://becominghuman.ai/learning-note-dropout-in-recurrent-networks-part-1-57a9c19a2307)  