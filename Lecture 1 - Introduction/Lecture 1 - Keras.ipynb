{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 1. Keras",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6xZha2jYQ-4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Введение в keras"
      ]
    },
    {
      "metadata": {
        "id": "F8RyqqwxMNK-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37QbrooERPEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sequential Model\n",
        "\n",
        "Обучить свою нейросеть просто! Нужно\n",
        "\n",
        "1.   Выбрать типы и последовательность слоев\n",
        "2.   Настроить параметры слоев (передав нужные в конструктор слоя или оставив вариант по умолчанию)\n",
        "3.   Выбрать оптимизатор и скомпилировать модель\n",
        "4.   Обучить модель!\n"
      ]
    },
    {
      "metadata": {
        "id": "_PL1yCgDatoO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Чтобы создать Sequential модель, просто позовите следующие строки:"
      ]
    },
    {
      "metadata": {
        "id": "CU_s-FGdastN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ukd2lt5_axi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Слои теперь добавляются в модель последовательно, как будто это list:"
      ]
    },
    {
      "metadata": {
        "id": "YjBDZ-3mM-aM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F63KsSzwa9Hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Только что мы создали сеть с одним скрытым слоем. Сколько в ней обучаемых параметров?\n",
        "\n",
        "Посмотреть это можно с помощью метода"
      ]
    },
    {
      "metadata": {
        "id": "Fjw85Mpya7uQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YA4XjeN-R1tw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Почему столько параметров в слоях?*\n",
        "\n",
        "*Что за `None` вместо первого элемента `Output Shape`?*"
      ]
    },
    {
      "metadata": {
        "id": "tLP-gPWObqD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Прежде чем обучать эту модель, её нужно скомпилировать:"
      ]
    },
    {
      "metadata": {
        "id": "13mCHIX_boaX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQglXsdgbsJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В NLP чаще всего ставятся задачи классификации, поэтому нужно запомнить такие функции потерь:\n",
        "\n",
        "\n",
        "*   **categorical_crossentropy** - для многоклассовой классификации, в качестве меток должны передаваться one-hot-encoding вектора\n",
        "*   **sparse_categorical_crossentropy** - аналогично предыдущему, но в качестве меток нужно передавать просто индексы соответствующих классов\n",
        "*   **binary_crossentropy** - для бинарной классификации\n",
        "\n",
        "\n",
        "В качестве оптимизатора обычно используют `sgd` или `adam`.\n"
      ]
    },
    {
      "metadata": {
        "id": "awWq_2TBeUDZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.random.randn(10000, 100)\n",
        "y_train = np.random.randint(0, 10, size=10000)\n",
        "X_test = np.random.randn(1000, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6ruHCW2bW2v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fofu9T-o9IIp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Binary Classification\n",
        "\n",
        "Попробуем предсказать сентимент (положительность/отрицательность) imdb'шных ревью [keras: IMDB Movie reviews sentiment classification](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification)"
      ]
    },
    {
      "metadata": {
        "id": "q-MKXv5o5Xdr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mmwhhax5k6G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "NUM_WORDS = 10000\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfSFPs6Y9Vhv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bag-of-words\n",
        "\n",
        "Начнем с простейшей модели"
      ]
    },
    {
      "metadata": {
        "id": "UINEdlb7555l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def convert_to_bow(X):\n",
        "  X_bow = np.zeros((len(X), NUM_WORDS))\n",
        "  for i, review in enumerate(X):\n",
        "    for ind in review:\n",
        "      X_bow[i, ind] = 1\n",
        "  return X_bow\n",
        "\n",
        "X_train_bow, X_test_bow = convert_to_bow(X_train), convert_to_bow(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldWyutMw7kYo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=NUM_WORDS))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J2ijwrONZFus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Как называется такая модель?*"
      ]
    },
    {
      "metadata": {
        "id": "SiDnmkwb73Ie",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_bow, y_train, \n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          validation_data=(X_test_bow, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Api85ure9o-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convs\n",
        "\n",
        "Переходим к более сложным моделям."
      ]
    },
    {
      "metadata": {
        "id": "-3P3ZLYq9TSn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "MAX_LEN = 400\n",
        "\n",
        "X_train_long = sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_test_long = sequence.pad_sequences(X_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztzPy24B-Gkk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Dropout, SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "EMB_DIM = 50\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=NUM_WORDS, \n",
        "                    output_dim=EMB_DIM, \n",
        "                    input_length=MAX_LEN))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(),  # оптимизатор ещё и так можно передавать\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNYoNaou_Iyx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_long, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test_long, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEwbwOVWZcsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Попробуем улучшить качество.\n",
        "\n",
        "Добавим предобученные словные эмбеддинги.\n",
        "\n",
        "Чёрная магия, которую нужно для этого скастовать, выглядит как-нибудь так:"
      ]
    },
    {
      "metadata": {
        "id": "NnEoksQx_ypD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install chakin\n",
        "\n",
        "import chakin\n",
        "chakin.search(lang='English')\n",
        "\n",
        "chakin.download(number=11, save_dir='./')\n",
        "\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "!pip install gensim\n",
        "!python -m gensim.scripts.glove2word2vec --input glove.6B.50d.txt --output glove.6B.50d.v2w.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlvSk2xrAr86",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word_vectors = KeyedVectors.load_word2vec_format('glove.6B.50d.v2w.txt', binary=False)\n",
        "\n",
        "glove_word2index = {w : i for i, w in enumerate(word_vectors.index2word)}\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "word_index_rev = {word_index[x] : x for x in word_index}\n",
        "\n",
        "embedding_matrix = 0.05 * np.random.randn(NUM_WORDS, EMB_DIM)\n",
        "\n",
        "num_of_known_words = 0\n",
        "for word in word_index:\n",
        "  ind = word_index[word] + 3\n",
        "  if ind < NUM_WORDS and word in glove_word2index:\n",
        "    embedding_matrix[ind] = word_vectors.vectors[glove_word2index[word]]\n",
        "    num_of_known_words += 1\n",
        "\n",
        "print('Know', num_of_known_words, 'out of', NUM_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cDUpRPkZnDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: Постройте ту же самую модель, но уже с передачей весов в `Embedding`.\n",
        "\n",
        "Обратите внимание на параметр `trainable`: во многих случаях дообучать эмбеддинги не нужно - для этого нужно передать `trainable=False`."
      ]
    },
    {
      "metadata": {
        "id": "Uk4LboZuDQ3t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "<your code. Use weights=[embedding_matrix] parameter of the Embedding layer>\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oLOKHOvFIlJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_long, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test_long, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HXQqJaifFhpx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM\n",
        "\n",
        "Попробуем теперь использовать рекуррентную сеть.\n",
        "\n",
        "Укоротим немного предложения для скорости:"
      ]
    },
    {
      "metadata": {
        "id": "hJGc8_0mHX4x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 80\n",
        "\n",
        "X_train_short = sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_test_short = sequence.pad_sequences(X_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63lFedATUsi_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: постройте модель с LSTM.\n",
        "Первым должен так и идти слой эмбеддингов, а LSTM - применяться поверх него. Результатом будет последнее предсказание LSTM - с учётом всего контекста.\n",
        "\n",
        "Интересные параметры LSTM:\n",
        "`LSTM(units=?, dropout=0.0, recurrent_dropout=0.0, return_sequences=False)`\n",
        "\n",
        "Попробуйте `units=64` и дропауты в районе 0.2.\n"
      ]
    },
    {
      "metadata": {
        "id": "bbE2DiFdFkE6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Bidirectional\n",
        "\n",
        "<your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfV68kl3F3_v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_short, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(X_test_short, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkrqb6lBV0Nu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM-CNN\n",
        "\n",
        "Вообще говоря, LSTM выдает не одно состояние, а много (внимание на `return_sequences`). Почему бы не попробовать использовать их все?\n",
        "\n",
        "**Задание**: реализуйте свертки и GlobalMaxPooling поверх выхода LSTM."
      ]
    },
    {
      "metadata": {
        "id": "65eD-ph4Vy_S",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "<your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lthq71WoPRZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Functional API\n",
        "\n",
        "Альтернативный (и более гибкий) вариант построения модели.\n",
        "\n",
        "Говоря по-сложному: у каждого объекта типа Layer переопределен метод `__call__`: его можно вызывать и передавать некоторый входной тензор. Возвращаемое значение - результат применения трансформации, задаваемой этим слоем, к данному входу (опять же тензор).\n",
        "\n",
        "А если по-простому - давайте построим ту же самую бессмысленную модель из самого начала ноутбука, но уже с новым апи."
      ]
    },
    {
      "metadata": {
        "id": "9s7epVrrPQdP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEkqYnxyPgEw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(100,))\n",
        "\n",
        "hidden_layer = Dense(units=64, activation='relu')(inputs)\n",
        "outputs = Dense(units=10, activation='softmax')(hidden_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TR7G0dHDRLsI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: сделайте модель, которая применяет свертки с шириной окна 2 и 3 к imdb dataset'у.\n",
        "\n",
        "Пригодится слой `concatenate` для объединения результатов разных типов сверток."
      ]
    },
    {
      "metadata": {
        "id": "Ux0XH6JBRLPA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate\n",
        "\n",
        "<your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSQ2yIq-IvQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multiclass Classification\n",
        "\n",
        "Переходим к многоклассовой классификации: [keras: Reuters newswire topics classification](https://keras.io/datasets/#reuters-newswire-topics-classification).\n",
        "\n",
        "У нас тут 11,228 новостей размеченных по 46 топикам."
      ]
    },
    {
      "metadata": {
        "id": "dILzHGLPHjFa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "NUM_WORDS = 10000\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=NUM_WORDS,\n",
        "                                                         test_split=0.2)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "num_classes = np.max(y_train) + 1\n",
        "print(num_classes, 'classes')\n",
        "\n",
        "print('Mean train example len:', np.mean([len(x) for x in X_train]))\n",
        "print('Mean test example len:', np.mean([len(x) for x in X_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Od-ulZLtJHtg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 150\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-C7uP-rMNIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: Попробуйте обучить собственную сеть на этих данных.\n",
        "\n",
        "Обратите внимание, что теперь уже многоклассовая классификация (вспоминаем про `sparse_categorical_crossentropy` и выходной слой с числом unit'ов, равным числу классов, и `softmax` активацией)."
      ]
    },
    {
      "metadata": {
        "id": "cjKlYJM_UaVj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "<your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SixEDc_cb__f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Классификация на уровне символов\n",
        "\n",
        "Попробуем вернуться к imdb и предсказывать слова, используя их символьное представление."
      ]
    },
    {
      "metadata": {
        "id": "wZtr-ETMb_TG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "NUM_WORDS = 50000\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "word_index_rev = {word_index[x] : x for x in word_index}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLq8Dv5SiE_f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Зададим отображение из символов в индексы."
      ]
    },
    {
      "metadata": {
        "id": "gE0uv6UmdzH8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def get_range(first_symb, last_symb):\n",
        "  return set(chr(c) for c in range(ord(first_symb), ord(last_symb) + 1))\n",
        "\n",
        "chars = get_range('a', 'z') | get_range('0', '9') | set(punctuation)\n",
        "char_index = {c : i for i, c in enumerate(chars)}\n",
        "\n",
        "def get_char_index(char, char_index):\n",
        "  return char_index[char] if char in char_index else len(char_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8RnGW9ziJ-v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Используя костыли, построим тензор, в котором на месте каждого элемента стоит последовательность его символов."
      ]
    },
    {
      "metadata": {
        "id": "hW6OmnCleLWK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_WORD_LEN = 15\n",
        "MAX_LINE_LEN = 100\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_LINE_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_LINE_LEN)\n",
        "\n",
        "def build_chars_tensor(X):\n",
        "  X_chars = np.zeros((len(X), MAX_LINE_LEN, MAX_WORD_LEN))\n",
        "  for i, line in enumerate(X):\n",
        "    for j, word_ind in enumerate(line):\n",
        "      if word_ind >= 3:\n",
        "        word = word_index_rev[word_ind]\n",
        "        word = word if len(word) < MAX_WORD_LEN else word[-MAX_WORD_LEN:]\n",
        "        X_chars[i, j, -len(word):] = [get_char_index(c, char_index) for c in word]\n",
        "  return X_chars\n",
        "\n",
        "X_chars_train = build_chars_tensor(X_train)\n",
        "X_chars_test = build_chars_tensor(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ga-z7dmwidVo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Какая размерность получится, если применить к этому тензору ещё и слой эмбеддингов?*\n",
        "\n",
        "**Задание**: допишите код, попробуйте поклассифицировать с помощью него."
      ]
    },
    {
      "metadata": {
        "id": "5kH5wL3egWiA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import TimeDistributed\n",
        "\n",
        "def build_chars_layer(chars_count, char_emb_dim=20, lstm_dim=32, dropout_rate=.2):\n",
        "  chars_embedding = Embedding(chars_count, char_emb_dim, name='char_embeddings')\n",
        "  chars_lstm = TimeDistributed(Bidirectional(\n",
        "      LSTM(lstm_dim, dropout=dropout_rate, recurrent_dropout=dropout_rate, name='char_LSTM')))\n",
        "  \n",
        "  def process_input(inp):\n",
        "    res = chars_embedding(inp)\n",
        "    return chars_lstm(res)\n",
        "  return process_input\n",
        "  \n",
        "chars = Input(shape=(None, MAX_WORD_LEN), name='chars')\n",
        "\n",
        "chars_level_embedding = build_chars_layer(chars_count = len(char_index) + 1)\n",
        "chars_output = chars_level_embedding(chars)\n",
        "\n",
        "<your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}