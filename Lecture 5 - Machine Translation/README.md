# Лекция 5
*Машинный перевод*

Ноутбук на Colab можно найти [здесь](https://colab.research.google.com/drive/1ZkxDQUcoc0LUjjiP6nlQwYuBPWLxZFZD).

**Задание**  
*Дедлайн: 09:00 GMT+3 09.04.18*  
Доделать Seq2Seq и Attention.

Дополнительные материалы:  
[Tensorflow: Neural Machine Translation (seq2seq) Tutorial](https://www.tensorflow.org/tutorials/seq2seq)  
[Oxford Deep NLP 2017: Lecture 8 - Generating Language with Attention](https://github.com/oxford-cs-deepnlp-2017/lectures#10-lecture-8---generating-language-with-attention-chris-dyer)   
[Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)   
[cs224n "Lecture 10: Neural Machine Translation and Models with Attention" (video)](https://www.youtube.com/watch?v=IxQtK2SjWWM&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&index=11&t=0s)